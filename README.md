
# OCR com OpenCV e Tesseract

Este projeto tem como objetivo a identifica√ß√£o de textos em imagem de forma satisfat√≥ria, utilizando OpenCV e Tesseract OCR para detectar e extrair texto de imagens, aplicando t√©cnicas avan√ßadas de processamento de imagem para melhorar a precis√£o da leitura.

## üìå Requisitos

Para executar o projeto, √© necess√°rio ter esses requisitos instalados:

- Python
- OpenCV (`cv2`)
- NumPy
- Pytesseract
- Imutils

Voc√™ pode instalar as depend√™ncias com o seguinte comando:

```sh
pip install opencv-python numpy pytesseract imutils
```
Tamb√©m √© necess√°rio ter o modelo EAST (Efficient and Accurate Scene Text detector) instalado, mas nesse projeto ele j√° est√° na pasta ./src

## üöÄ Como executar

1. Certifique-se de que a imagem a ser processada est√° localizada no diret√≥rio `./src/` e ajustada no c√≥digo (`image = cv2.imread('./src/placarj.webp')`).
2. Execute o script Python:

```sh
python script.py
```

3. O script processar√° a imagem e imprimir√° o texto extra√≠do no console.

## üîç Como funciona

O processo de OCR segue as seguintes etapas:

1. **Defini√ß√£o de constantes**
S√£o definidas a configural√ß√£o do tesseract a ser utilizada, o caminho para a imagem que ser√° feita a leitura, o caminho para o modelo EAST e as camadas do modelo que ser√£o utilizadas. Segue abaixo o c√≥digo: 

```python
config_tesseract = '--oem 3 --psm 6'
image = cv2.imread('./src/placarj.webp')

model = "./src/frozen_east_text_detection.pb"
layers = ['feature_fusion/Conv_7/Sigmoid', 'feature_fusion/concat_3']
```

2. **Detec√ß√£o de texto com EAST**
Aqui √© onde se define um novo tamanho para a imagem e √© mudada para o formato blob, de forma que o modelo consiga fazer a leitura dela. Ent√ßao come√ßa a execu√ß√£o do modelo, usando essa imagem em formado blob como input e ent√£o s√£o extra√≠dos os resultados de n√≠vel de confian√ßa e localiza√ß√£o de textos na imagem, que s√£o definidos como scores e geometry respectivamente:

```python
modelW, modelH = 320,320
image_resized = cv2.resize(image, (modelW, modelH))
blob = cv2.dnn.blobFromImage(image_resized, 1.0, (modelW, modelH), swapRB=True, crop=False)
neural_network = cv2.dnn.readNet(model)
neural_network.setInput(blob)
scores, geometry = neural_network.forward(layers)
```

3. **Defini√ß√£o de vari√°veis a serem usadas para armazenar e identificar as caixas a serem utilizadas**
Se √© extra√≠do a quantidade de linhas e colunas da matriz scores. Cada c√©lula dessa grade cont√©m um valor de confian√ßa sobre a presen√ßa de texto naquela regi√£o da imagem. √â definida a vari√°vel que define o nivel minimo de confian√ßa para considerarmos o bounding box, se cria um array de boxes para armazenamento dessas bounding boxes e por fim √© criado um array de confidences que armazena o nivel de confian√ßa dessas bounding boxes escolhidas a partir do nivel de confian√ßa:

```python
lines, columns = scores.shape[2:4]
confidence_level = 0.8
boxes = []
confidences = []
```
4. **Processamento dos dados para identificar bounding boxes a serem usados**
Ap√≥s todas essas defini√ß√µes, √© come√ßado o processo para identificar os melhores bounding boxes paraserem utilizar na imagem. Esse processamento dos dados √© feito com auxilio de tr√™s fun√ß√µes que est√£o no arquivo './helpres.py':

- geometry_data(geometry, y): extrai os dados de distancia entre o centro da imagem e o topo, direita, base e esquerda da iamgem na respectiva posi√ß√£o y do array geometry. Tamb√© se √© extra√≠do angulo de inclina√ß√£o.

- calc_geo(data_dtop, data_dright, data_dbottom, data_dleft, data_angle, x, y):  calcula a altura, largura e o angulo de inclina√ß√£o do bounding box s√≥ que na imagem original, baseado nos dados extra√≠dos retornados de geometry_data.

- merge_boxes(boxes, threshold_distance=20, overlap_threshold = 0.1): Identifica bounding boxes que estejam muito proximos ou que estejam tendo sobreposi√ß√£o um com o outro e ent√£o √© feito o merge deles para serem apenas uma box.

4. **Pr√©-processamento**: As regi√µes de interesse (ROI) passam por t√©cnicas como binariza√ß√£o, eros√£o e dilata√ß√£o baseadas na valor m√©dio dos pixels encontrados na imagem.

5. **Reconhecimento de texto com Tesseract**: As regi√µes processadas s√£o passadas para o Tesseract OCR para extra√ß√£o do texto.

6. **P√≥s-processamento**: Remo√ß√£o de caracteres indesejados e ajustes na formata√ß√£o do texto extra√≠do.

## üìÇ Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ placarj.webp  # Imagem de exemplo
‚îÇ   ‚îú‚îÄ‚îÄ foto.jpg  # Imagem de exemplo
‚îÇ   ‚îú‚îÄ‚îÄ frozen_east_text_detection.pb  # Modelo EAST
‚îú‚îÄ‚îÄ helpers.py  # Fun√ß√µes auxiliares para c√°lculos geom√©tricos e fus√£o de caixas
‚îú‚îÄ‚îÄ app.py  # C√≥digo principal do OCR
‚îî‚îÄ‚îÄ README.md
```

## üìå Configura√ß√£o do Tesseract

Certifique-se de que o Tesseract est√° instalado e acess√≠vel pelo Python. Caso necess√°rio, instale manualmente:

- **Windows**: Baixe e instale a vers√£o do [Tesseract OCR](https://github.com/UB-Mannheim/tesseract/wiki).
- **Linux**: Instale via terminal:

```sh
sudo apt-get install tesseract-ocr
```

Caso o Tesseract n√£o esteja no caminho padr√£o, defina sua localiza√ß√£o no c√≥digo:

```python
pytesseract.pytesseract.tesseract_cmd = "C:/Program Files/Tesseract-OCR/tesseract.exe"
```

